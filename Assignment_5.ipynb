{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNyZv-Ec52ot",
        "colab_type": "text"
      },
      "source": [
        "# **Import Libraries and modules**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUbc_ugOPjKP",
        "colab_type": "text"
      },
      "source": [
        "**the iterations are explained in the convolution block**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m3w1Cw49Zkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eso6UHE080D4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add,BatchNormalization\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import regularizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zByEi95J86RD",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-shuffled MNIST data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRM0QWN83PV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlTm5VZ3--UC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "width, height, channels = X_train.shape[1], X_train.shape[2], 1\n",
        "X_train = X_train.reshape((X_train.shape[0], width, height, channels))\n",
        "X_test = X_test.reshape((X_test.shape[0], width, height, channels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CcF84aoBOay",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5bfe8678-bac8-4161-9dce-1b206b132ae8"
      },
      "source": [
        "print('Statistics train=%.3f (%.3f), test=%.3f (%.3f)' % (X_train.mean(), X_train.std(), X_test.mean(), X_test.std()))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Statistics train=33.318 (78.567), test=33.791 (79.172)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a4Be72j8-ZC",
        "colab_type": "code",
        "outputId": "5b01a35e-37af-4f47-8ba5-fb42d157a754",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-082fa592d9dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2698\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[0;32m-> 2699\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2700\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2701\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5492\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5494\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5495\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    636\u001b[0m         if not (self._A.ndim == 2\n\u001b[1;32m    637\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[0;32m--> 638\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid dimensions for image data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid dimensions for image data"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNYZBUmMYJDWGQVJjGCQ1/wMKpFHVdp3xCwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkmprriw9AnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2m4YS4E9CRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndeMtfbKBUe0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a5153a40-8cda-4450-b69d-cd0554842699"
      },
      "source": [
        "print('Statistics train=%.3f (%.3f), test=%.3f (%.3f)' % (X_train.mean(), X_train.std(), X_test.mean(), X_test.std()))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Statistics train=0.131 (0.308), test=0.133 (0.310)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mn0vAYD9DvB",
        "colab_type": "code",
        "outputId": "4f5c3878-a563-48a2-e2d4-3a3bcd9f3b12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG8JiXR39FHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYlFRvKS9HMB",
        "colab_type": "code",
        "outputId": "bc891b0a-b6f4-43a0-fa8d-75fe837fb346",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "Y_train[:10]\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wg1_LYI-dSvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBGOpxizdS3x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "451a4fc4-e5ed-478c-e28f-e2f5f1db2e80"
      },
      "source": [
        "datagen.fit(X_train)\n",
        "print('Data Generator mean=%.3f, std=%.3f' % (datagen.mean, datagen.std))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Generator mean=0.131, std=0.308\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLXmM5GHfYJS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iterator = datagen.flow(X_train, Y_train, batch_size=len(X_train), shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsH2Qt9Pfim9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batchX, batchy = iterator.next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_sxo7NrfoOJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1648bc23-8c4d-4234-e684-405f1db3ddc2"
      },
      "source": [
        "print(batchX.shape, batchX.mean(), batchX.std())"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1) -4.9324944e-07 0.9999959\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osKqT73Q9JJB",
        "colab_type": "code",
        "outputId": "2bd6e476-632f-427e-9f14-7aaf1df0b0a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        "\n",
        " \n",
        "model.add(Convolution2D(10, 3, 3, input_shape=(28,28,1)))#26*26*10\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, kernel_regularizer=regularizers.l2(0.01)))#24*24*16\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Convolution2D(32, 3, 3, kernel_regularizer=regularizers.l2(0.01)))#22*22*32\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dropout(0.10))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))#11*11*32\n",
        "\n",
        "model.add(Convolution2D(10, 1, kernel_regularizer=regularizers.l2(0.01)))#11*11*10\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, kernel_regularizer=regularizers.l2(0.01)))#9*9*16\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Convolution2D(10, 1, kernel_regularizer=regularizers.l2(0.01)))#9*9*10\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, kernel_regularizer=regularizers.l2(0.01)))#7*7*1\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Convolution2D(10, 1, kernel_regularizer=regularizers.l2(0.01)))#7*7*10\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "'''model.add(Convolution2D(32, 3, 3, activation='relu'))\n",
        "model.add(Convolution2D(10, 1, activation='relu'))'''\n",
        "\n",
        "model.add(Dropout(0.10))\n",
        "\n",
        "model.add(Convolution2D(10, 7, kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), kernel_regularizer=<keras.reg...)`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), kernel_regularizer=<keras.reg...)`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), kernel_regularizer=<keras.reg...)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fck-WNu1Pq2Z",
        "colab_type": "text"
      },
      "source": [
        "**In the convolution block the L2 regularisation was done ,\n",
        "The relu activation was performed after batch normalisation and image normalisation is also done before the convolution blockt**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzdAYg1k9K7Z",
        "colab_type": "code",
        "outputId": "b920e9a9-2782-413b-8728-b99995857820",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1190
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_10 (Conv2D)           (None, 26, 26, 10)        100       \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 26, 26, 10)        40        \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 26, 26, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 24, 24, 16)        1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 24, 24, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 22, 22, 32)        4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 22, 22, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 22, 22, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 22, 22, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 11, 11, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 11, 11, 10)        330       \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 11, 11, 10)        40        \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 11, 11, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 9, 9, 16)          1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 9, 9, 16)          64        \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 9, 9, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 9, 9, 10)          170       \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 9, 9, 10)          40        \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 9, 9, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 7, 7, 16)          1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 7, 7, 16)          64        \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 7, 7, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 7, 7, 10)          170       \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 7, 7, 10)          40        \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 7, 7, 10)          0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 7, 7, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 1, 1, 10)          4910      \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 1, 1, 10)          40        \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 15,208\n",
            "Trainable params: 14,948\n",
            "Non-trainable params: 260\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp6SuGrL9M3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xWoKhPY9Of5",
        "colab_type": "code",
        "outputId": "6e7b5e07-3cb8-4b57-c9ab-bbaac5fc1c9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2771
        }
      },
      "source": [
        "i=0\n",
        "def bestval(val_acc):\n",
        "  if(i==0):\n",
        "    oldval=val_acc\n",
        "    model.save()\n",
        "  else:\n",
        "    if(val_acc>oldval):\n",
        "      model.save()\n",
        "      oldval=val_acc\n",
        "      i+=1\n",
        "    \n",
        "    \n",
        "  \n",
        "model.fit(batchX, batchy, batch_size=256, epochs=40, verbose=1, validation_data=(X_test, Y_test), callbacks=[LearningRateScheduler(scheduler, verbose=1)])\n"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/40\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.1760 - acc: 0.9823 - val_loss: 2.1772 - val_acc: 0.3111\n",
            "Epoch 2/40\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.1377 - acc: 0.9846 - val_loss: 1.2558 - val_acc: 0.6694\n",
            "Epoch 3/40\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "60000/60000 [==============================] - 4s 75us/step - loss: 0.1184 - acc: 0.9858 - val_loss: 0.6637 - val_acc: 0.8223\n",
            "Epoch 4/40\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "60000/60000 [==============================] - 4s 75us/step - loss: 0.1067 - acc: 0.9862 - val_loss: 0.5649 - val_acc: 0.8976\n",
            "Epoch 5/40\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0945 - acc: 0.9884 - val_loss: 1.2580 - val_acc: 0.5984\n",
            "Epoch 6/40\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0894 - acc: 0.9876 - val_loss: 0.8003 - val_acc: 0.7835\n",
            "Epoch 7/40\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0834 - acc: 0.9883 - val_loss: 0.4540 - val_acc: 0.8796\n",
            "Epoch 8/40\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0770 - acc: 0.9897 - val_loss: 0.6444 - val_acc: 0.8122\n",
            "Epoch 9/40\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0719 - acc: 0.9905 - val_loss: 0.2782 - val_acc: 0.9393\n",
            "Epoch 10/40\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0713 - acc: 0.9897 - val_loss: 0.4567 - val_acc: 0.8565\n",
            "Epoch 11/40\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0642 - acc: 0.9911 - val_loss: 0.2741 - val_acc: 0.9318\n",
            "Epoch 12/40\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0618 - acc: 0.9911 - val_loss: 0.1990 - val_acc: 0.9525\n",
            "Epoch 13/40\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0593 - acc: 0.9916 - val_loss: 0.4789 - val_acc: 0.8502\n",
            "Epoch 14/40\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0569 - acc: 0.9917 - val_loss: 0.2359 - val_acc: 0.9464\n",
            "Epoch 15/40\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "60000/60000 [==============================] - 4s 73us/step - loss: 0.0555 - acc: 0.9919 - val_loss: 0.2791 - val_acc: 0.9364\n",
            "Epoch 16/40\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "60000/60000 [==============================] - 4s 73us/step - loss: 0.0522 - acc: 0.9925 - val_loss: 0.1959 - val_acc: 0.9523\n",
            "Epoch 17/40\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "60000/60000 [==============================] - 4s 73us/step - loss: 0.0511 - acc: 0.9924 - val_loss: 0.2025 - val_acc: 0.9588\n",
            "Epoch 18/40\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "60000/60000 [==============================] - 4s 73us/step - loss: 0.0492 - acc: 0.9928 - val_loss: 0.6986 - val_acc: 0.7627\n",
            "Epoch 19/40\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0462 - acc: 0.9938 - val_loss: 0.3876 - val_acc: 0.8937\n",
            "Epoch 20/40\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0451 - acc: 0.9934 - val_loss: 0.3916 - val_acc: 0.8750\n",
            "Epoch 21/40\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0004065041.\n",
            "60000/60000 [==============================] - 4s 75us/step - loss: 0.0443 - acc: 0.9938 - val_loss: 0.3406 - val_acc: 0.9044\n",
            "Epoch 22/40\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000389661.\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0423 - acc: 0.9941 - val_loss: 0.2322 - val_acc: 0.9367\n",
            "Epoch 23/40\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0003741581.\n",
            "60000/60000 [==============================] - 4s 75us/step - loss: 0.0419 - acc: 0.9936 - val_loss: 0.6234 - val_acc: 0.7913\n",
            "Epoch 24/40\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0003598417.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0398 - acc: 0.9943 - val_loss: 0.4226 - val_acc: 0.8707\n",
            "Epoch 25/40\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0003465804.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0385 - acc: 0.9948 - val_loss: 0.2035 - val_acc: 0.9461\n",
            "Epoch 26/40\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0003342618.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0374 - acc: 0.9946 - val_loss: 0.3826 - val_acc: 0.8848\n",
            "Epoch 27/40\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0003227889.\n",
            "60000/60000 [==============================] - 4s 73us/step - loss: 0.0381 - acc: 0.9942 - val_loss: 0.2994 - val_acc: 0.9172\n",
            "Epoch 28/40\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0003120774.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0359 - acc: 0.9954 - val_loss: 0.3981 - val_acc: 0.8798\n",
            "Epoch 29/40\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000302054.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0351 - acc: 0.9951 - val_loss: 0.3328 - val_acc: 0.9004\n",
            "Epoch 30/40\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0002926544.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0335 - acc: 0.9951 - val_loss: 0.3697 - val_acc: 0.8901\n",
            "Epoch 31/40\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0002838221.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0337 - acc: 0.9952 - val_loss: 0.4309 - val_acc: 0.8649\n",
            "Epoch 32/40\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0002755074.\n",
            "60000/60000 [==============================] - 4s 73us/step - loss: 0.0325 - acc: 0.9953 - val_loss: 0.2552 - val_acc: 0.9267\n",
            "Epoch 33/40\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.000267666.\n",
            "60000/60000 [==============================] - 4s 73us/step - loss: 0.0310 - acc: 0.9960 - val_loss: 0.2088 - val_acc: 0.9405\n",
            "Epoch 34/40\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0002602585.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0310 - acc: 0.9957 - val_loss: 0.2048 - val_acc: 0.9439\n",
            "Epoch 35/40\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.00025325.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0293 - acc: 0.9963 - val_loss: 0.1850 - val_acc: 0.9517\n",
            "Epoch 36/40\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0002466091.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0295 - acc: 0.9959 - val_loss: 0.3121 - val_acc: 0.9084\n",
            "Epoch 37/40\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0002403076.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0297 - acc: 0.9958 - val_loss: 0.2884 - val_acc: 0.9199\n",
            "Epoch 38/40\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0002343201.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0287 - acc: 0.9958 - val_loss: 0.5551 - val_acc: 0.8132\n",
            "Epoch 39/40\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0002286237.\n",
            "60000/60000 [==============================] - 4s 75us/step - loss: 0.0288 - acc: 0.9959 - val_loss: 0.3570 - val_acc: 0.8850\n",
            "Epoch 40/40\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0002231977.\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.0270 - acc: 0.9966 - val_loss: 0.3413 - val_acc: 0.8949\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe36c49d2e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFALaF9D5p-3",
        "colab_type": "text"
      },
      "source": [
        "Im not sure how to save the best validation accuracy or how to make the 25 misclassified images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtsH-lLk-eLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkX8JMv79q9r",
        "colab_type": "code",
        "outputId": "e4b20f2a-1a57-4379-f586-7ed50b660237",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.3412800203204155, 0.8949]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCWoJkwE9suh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym7iCFBm9uBs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(y_pred[:9])\n",
        "print(y_test[:9])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT--y98_dr2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_dict = dict([(layer.name, layer) for layer in model.layers])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GY4Upv4dsUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from keras import backend as K\n",
        "%matplotlib inline\n",
        "# util function to convert a tensor into a valid image\n",
        "def deprocess_image(x):\n",
        "    # normalize tensor: center on 0., ensure std is 0.1\n",
        "    x -= x.mean()\n",
        "    x /= (x.std() + 1e-5)\n",
        "    x *= 0.1\n",
        "\n",
        "    # clip to [0, 1]\n",
        "    x += 0.5\n",
        "    x = np.clip(x, 0, 1)\n",
        "\n",
        "    # convert to RGB array\n",
        "    x *= 255\n",
        "    #x = x.transpose((1, 2, 0))\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x\n",
        "\n",
        "def vis_img_in_filter(img = np.array(X_train[2]).reshape((1, 28, 28, 1)).astype(np.float64), \n",
        "                      layer_name = 'conv2d_14'):\n",
        "    layer_output = layer_dict[layer_name].output\n",
        "    img_ascs = list()\n",
        "    for filter_index in range(layer_output.shape[3]):\n",
        "        # build a loss function that maximizes the activation\n",
        "        # of the nth filter of the layer considered\n",
        "        loss = K.mean(layer_output[:, :, :, filter_index])\n",
        "\n",
        "        # compute the gradient of the input picture wrt this loss\n",
        "        grads = K.gradients(loss, model.input)[0]\n",
        "\n",
        "        # normalization trick: we normalize the gradient\n",
        "        grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
        "\n",
        "        # this function returns the loss and grads given the input picture\n",
        "        iterate = K.function([model.input], [loss, grads])\n",
        "\n",
        "        # step size for gradient ascent\n",
        "        step = 5.\n",
        "\n",
        "        img_asc = np.array(img)\n",
        "        # run gradient ascent for 20 steps\n",
        "        for i in range(20):\n",
        "            loss_value, grads_value = iterate([img_asc])\n",
        "            img_asc += grads_value * step\n",
        "\n",
        "        img_asc = img_asc[0]\n",
        "        img_ascs.append(deprocess_image(img_asc).reshape((28, 28)))\n",
        "        \n",
        "    if layer_output.shape[3] >= 35:\n",
        "        plot_x, plot_y = 6, 6\n",
        "    elif layer_output.shape[3] >= 23:\n",
        "        plot_x, plot_y = 4, 6\n",
        "    elif layer_output.shape[3] >= 11:\n",
        "        plot_x, plot_y = 2, 6\n",
        "    else:\n",
        "        plot_x, plot_y = 1, 2\n",
        "    fig, ax = plt.subplots(plot_x, plot_y, figsize = (12, 12))\n",
        "    ax[0, 0].imshow(img.reshape((28, 28)), cmap = 'gray')\n",
        "    ax[0, 0].set_title('Input image')\n",
        "    fig.suptitle('Input image and %s filters' % (layer_name,))\n",
        "    fig.tight_layout(pad = 0.3, rect = [0, 0, 0.9, 0.9])\n",
        "    for (x, y) in [(i, j) for i in range(plot_x) for j in range(plot_y)]:\n",
        "        if x == 0 and y == 0:\n",
        "            continue\n",
        "        ax[x, y].imshow(img_ascs[x * plot_y + y - 1], cmap = 'gray')\n",
        "        ax[x, y].set_title('filter %d' % (x * plot_y + y - 1))\n",
        "\n",
        "vis_img_in_filter()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tvptcn8dxvp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}